# Fichamento PPGI

<br>

Tags: `intro`, `just`, `alinhamento`, `motivação`, `obesp`, `obgeral`, `fundteo`, `analise`, `etica`, `result`, `contrib`.

<br>

1. [Speech Emotion Recognition using Supervised Deep Recurrent System for Mental Health Monitoring](https://arxiv.org/abs/2208.12812)

<details>
<summary>[+]</summary>

`#intro`

"Understanding human behavior and monitoringmental health are essential to maintaining the community and society’s safety"

"According to the Institute for Health Metrics and Evaluation (IHME), the number of diagnosed individuals with one of the mental disorders globally has exceeded 1.1 billion individuals in 2016 [2]"

"Due to late or unreceived mental care, the number of relatedsuicide has increased as well. The number of suicides has exceeded 700,000, meaning one person every 40 seconds dies by suicidal action related to a mental disorder [3]"

"Speech is the primary form of communication and emotional expression [5]. From childhood, even before being able to speak correct words, children express their emotions in their ununderstandable talks, such as their happiness and confusion. Juvenile, adults, and elderly individuals also express their emotions in their speech. All individuals express common emotions such as happy, sad, angry, happy, worry, fear, and neutral in their speech. However, different spoken languages produce differences in how these emotions are expressed in the speech tone and voice [6], [7]"

"There are several mental disorders that can be identified from individual’s emotion changes [9], [10] such as depression disorder [11], [12], stress disorder [13], [14], and anxiety (worry/fear) disorders [15], [16]. Early diagnostic of mental disorders allows the individual to recieve the correct treatment and prevent sever illensses and even protect fom suisidal action [17], [18]."

"Several studies address the effect of the IVA devices on individuals’ social life [24], markating [25], and social communication [26]. However, there are few studies on understanding the user behavior while using intelligent virtual personal assistant devices to improve the user experience. Yang et al. [27] attempted to understand how to improve the IVA user experience by investigating the relationship between perceived enjoyment, perceived usefulness, and product-related characteristics using a user survey"

`#fundteo`

"Zhang et al. [32], Bhargava et al. [33], Krishnan et al. [34], and Venkataramanan et al. [29] proposed different machine learning and deep learning approaches to solve the speech emotion recognition under the scenario I {{ designing a model that used speech signal datasets after performing data preprocessing and feature extraction }} approach"

"The GRU has successfully achieved significant results in various applications, especially in signal data such as emotion recognition from EEG signal [37], sleep stage classification from EEG and EoG [38], arrhythmia supraventricular premature beat detection from ECG signal [39], music source separation [40], and sound event detection [41]. GRU can learn the spatial features of the speech signal and the temporal information due to the recurrent behavior. In this paper, we selected the GRU as a competitive recurrent neural network that requires less budget and can achieve comparable results to the LSTM. The 1D-CNN acts as the feature extractor for the 1D speech signal [42]–[44]."

`#motiv`

"Personal emotion is one of the most significant indicators of mental health normality and issues."

"The model can be applied within an intelligent virtual personal assistant to improve the user experience while combining the user request and emotion to provide the appropriate service"

</details>

___
2. [Depression Recognition using Remote Photoplethysmography from Facial Videos](https://arxiv.org/abs/2206.04399) -> [???]()

<details>

<summary>[+]</summary>



</details>

___
3. [Accurate Emotion Strength Assessment for Seen and Unseen Speech Based on Data-Driven Deep Learning](https://arxiv.org/abs/2206.07229) -> [???]()   

<details>

<summary>[+]</summary>



</details>

___
4. [Emotional Speaker Identification using a Novel Capsule Nets Model](https://arxiv.org/abs/2201.02994) -> [???]()

<details>

<summary>[+]</summary>



</details>


___
5. [MEL Spectrogram](https://medium.com/analytics-vidhya/understanding-the-mel-spectrogram-fca2afa2ce53) -> [???]()

<details>

<summary>[+]</summary>



</details>

___
6. [Automatic Detection of Depression from Stratified Samples of Audio Data](https://arxiv.org/abs/2111.10783) -> [???]()

<details>

<summary>[+]</summary>



</details>

___
7. [Automated Sex Classification of Children's Voices and Changes in Differentiating Factors with Age](https://arxiv.org/abs/2209.13112) -> [???]()

<details>

<summary>[+]</summary>



</details>

___
8. [Language Independent Emotion Quantification using Non linear Modelling of Speech](https://arxiv.org/abs/2102.06003) -> [???]()

<details>

<summary>[+]</summary>



</details>

___
9. [Voice Conversion Based on Cross-Domain Features Using Variational Auto Encoders](https://arxiv.org/abs/1808.09634) -> [???]()

<details>

<summary>[+]</summary>



</details>

___
10. [A Fine-tuned Wav2vec 2.0/HuBERT Benchmark For Speech Emotion Recognition, Speaker Verification and Spoken Language Understanding](https://arxiv.org/abs/2111.02735) -> [???]()

<details>

<summary>[+]</summary>



</details>

___
11. [Improving Automatic Emotion Recognition from speech using Rhythm and Temporal feature](https://arxiv.org/abs/1303.1761) -> [???]()

<details>

<summary>[+]</summary>



</details>

___
12. [DEEP: Uma arquitetura para reconhecer emoção com base no espectro sonoro da voz de falantes da língua portuguesa](https://bdm.unb.br/bitstream/10483/27583/1/2020_GabrielCampos_LucasMoutinho_tcc.pdf) -> [???]()

<details>

<summary>[+]</summary>



</details>

___
13. [A Knowledge-Based Recommendation System That Includes Sentiment Analysis and Deep Learning](https://ieeexplore.ieee.org/document/8445585) -> [???]()

<details>

<summary>[+]</summary>



</details>

___
14. [Emotion intensity detection for social media data](https://www.semanticscholar.org/paper/Emotion-intensity-detection-for-social-media-data-Mashal-Asnani/b28f0916e14c65af4d5f6ec0a3584251b78dc513) -> [???]()

<details>

<summary>[+]</summary>



</details>

___
15. [Emotion Detection and Analysis on Social Media](https://arxiv.org/abs/1901.08458) -> [???]()

<details>

<summary>[+]</summary>



</details>

___
16. [The paradoxical role of emotional intensity in the perception of vocal affect](https://www.nature.com/articles/s41598-021-88431-0) -> [???]()

<details>

<summary>[+]</summary>



</details>

___
17. [Human Emotion Recognition: Review of Sensors and Methods ](https://www.mdpi.com/1424-8220/20/3/592) -> [???]()

<details>

<summary>[+]</summary>



</details>

___
18. [Emotion Intensity and its Control for Emotional Voice Conversion](https://arxiv.org/abs/2201.03967) -> [???]()

<details>

<summary>[+]</summary>



</details>

___
19. [Emotional Intensity Level Analysis of Speech Emotional Intensity Estimation](https://www.esann.org/sites/default/files/proceedings/2021/ES2021-118.pdf) -> [???]()

<details>

<summary>[+]</summary>



</details>

___
20. [Recognition of Emotion with Intensity from Speech Signal Using 3D Transformed Feature and Deep Learning](https://www.mdpi.com/2079-9292/11/15/2362) -> [???]()

<details>

<summary>[+]</summary>



</details>

___
21. [Brazilian Portuguese emotional speech corpus analysis](https://www.gov.br/cti/pt-br/publicacoes/producao-cientifica/seminario-pci/xi_seminario_pci-2021/pdf/seminario-2021_paper_29.pdf) -> [???]() 

<details>

<summary>[+]</summary>



</details>

___
22. [END-TO-END SPEECH RECOGNITION APPLIED TO BRAZILIAN PORTUGUESE USING DEEP LEARNING](http://www.pee.ufrj.br/mwg-internal/de5fs23hu73ds/progress?id=ynpPt7kh6WfQgOdd36Ib7avR6tKN6V-l8iTIWXdw74o,&dl) -> [???]()

<details>

<summary>[+]</summary>



</details>

___
23. [StrengthNet: Deep Learning-based Emotion Strength Assessment for Emotional Speech Synthesis](https://arxiv.org/abs/2110.03156) -> [???]()

<details>

<summary>[+]</summary>



</details>

___
24. [Musical Genre Classification with Convolutional Neural Networks](https://towardsdatascience.com/musical-genre-classification-with-convolutional-neural-networks-ff04f9601a74) -> [???]()

<details>

<summary>[+]</summary>



</details>

___
25. [The circumplex model of affect: An integrative approach to affective neuroscience, cognitive development, and psychopathology](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2367156/) -> [???]()

<details>

<summary>[+]</summary>



</details>

___
26. [Russell’s (1980) Circumplex Models](https://psu.pb.unizin.org/psych425/chapter/circumplex-models/) -> [???]()

<details>

<summary>[+]</summary>



</details>

___
27. [O afeto sob a perspectiva do circumplexo: evidências de validade de construto](http://pepsic.bvsalud.org/scielo.php?script=sci_arttext&pid=S1677-04712017000200005) -> [???]()

<details>

<summary>[+]</summary>



</details>

___
28. [All-in-One: Emotion, Sentiment and Intensity Prediction using a Multi-task Ensemble Framework](https://www.cse.iitb.ac.in/~pb/papers/ieee-toac-sa.pdf) -> [???]()

<details>

<summary>[+]</summary>



</details>

___
29. [A Multi-task Ensemble Framework for Emotion, Sentiment and Intensity Prediction](https://arxiv.org/abs/1808.01216) -> [???]()

<details>

<summary>[+]</summary>



</details>

___
30. [Music emotion recognition based on segment-level two-stage learning](https://link.springer.com/content/pdf/10.1007/s13735-022-00230-z.pdf) -> [???]()

<details>

<summary>[+]</summary>



</details>

___
31. [Emotion Recognition from Speech: An Unsupervised Learning Approach](https://www.atlantis-press.com/journals/ijcis/125945494/view) -> [???]()

<details>

<summary>[+]</summary>



</details>

___
32. [Deep Learning Techniques for Speech Emotion Recognition, from Databases to Models](https://www.mdpi.com/1424-8220/21/4/1249) -> [???]()

<details>

<summary>[+]</summary>



</details>

___
33. [A voice-based real-time emotion detection technique using recurrent neural network empowered feature modelling](https://link.springer.com/content/pdf/10.1007/s11042-022-13363-4.pdf) -> [???]()

<details>

<summary>[+]</summary>



</details>

___
34. [UNSUPERVISED LEARNING APPROACH TO FEATURE ANALYSIS FOR AUTOMATIC SPEECH EMOTION RECOGNITION](http://labsites.rochester.edu/air/publications/eskimez2018unsupervised.pdf) -> [???]()

<details>

<summary>[+]</summary>



</details>

___
35. [Unsupervised Feature Learning for Speech Emotion Recognition Based on Autoencoder](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&ved=2ahUKEwjUpOOR54P7AhXOupUCHRf4BW4QFnoECAsQAQ&url=https%3A%2F%2Fwww.mdpi.com%2F2079-9292%2F10%2F17%2F2086%2Fpdf-vor&usg=AOvVaw2v1k9G3XnHqMWDkWOL8wdR) -> [???]()

<details>

<summary>[+]</summary>



</details>

___
36. [Speech Emotion Recognition Using Unsupervised Feature Selection Algorithms](https://www.semanticscholar.org/paper/Speech-Emotion-Recognition-using-Unsupervised-Bandela-Kumar/e8d637f9f02a8c4849e5af09e6b9f9edf5e76eb9) -> [???]()

<details>

<summary>[+]</summary>



</details>

___
37. [Survey of Deep Representation Learning for Speech Emotion Recognition](https://www.semanticscholar.org/paper/Survey-of-Deep-Representation-Learning-for-Speech-Latif-Rana/368e0844bbd3feb5ab17a271ad1663ca5a6fb7e7) -> [???]()

<details>

<summary>[+]</summary>



</details>

___
38. [Emotion classification from speech signal based on empirical mode decomposition and non-linear features](https://d-nb.info/1232071765/34) -> [???]()

<details>

<summary>[+]</summary>



</details>

<br><br>


Dataset | URL
------- | ---
VERBO   | https://github.com/jrtorresneto/VERBO-emotional-speech-dataset
VIVAE   | https://zenodo.org/record/4066235#.Y2FyG99v-Ul


<br><br>


Emoção              | VERBO | VIVAE | [x]
------------------- | ----- | ----- | ----
alegria / pleasure  | [x]   | [x]   | alegria
nojo / --           | [x]   | [ ]   |
medo / fear         | [x]   | [x]   | medo
neutro / --         | [x]   | [ ]   |
raiva / anger       | [x]   | [x]   | raiva
surpresa / surprise | [x]   | [x]   | surpresa
tristeza / --       | [x]   | [ ]   |
-- / pain           | [ ]   | [x]   |
-- / achievement    | [ ]   | [x]   |
