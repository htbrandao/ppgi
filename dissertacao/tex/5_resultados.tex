% \chapter{Resultados}\label{Cap:Resultados}

Neste capítulo serão apresentados os detalhes da implementação, resultados, métricas de desempenho e a metodologia utilizada na avaliação deste trabalho.\\

\section{Cenários Modelados}\label{sec:implementacao}

Esta seção detalha nossa implementação para o efetuar o reconhecimento da intensidade emoções na fala em nosso idioma nativo. Utilizando aprendizagem supervisionadas e não supervisionada para uma tarefa de reconhecimento da intensidade da emoção expressa vocalmente.

Para tanto, em virtude do desafio da demanda, ratificado pela escassez de dados, nos aproveitamos da Fusão de Dados para criar, primeiramente, uma solução não supervisionada que consiga extrair características que sejam representativas o suficiente para que, mesmo com a dimensionalidade reduzida em comparação a original, consigamos reconstruir o dado de entrada; e posteriomente utilizar esses dados comprimidos, constituído de atributos suficientemente relevantes, para desenvolver um modelo supervisionado de inferência da intensidade.

Definida a arquitetura composta por um Autoencoder e um Classificador, tomamos apenas as emoções comuns entre as duas bases de dados (alegria, medo, raiva e surpresa), totalizando 1364 registros, onde 51\% apresentam a o \textit{label} relativo a intensidade. %A Figura \ref{fig:design} apresenta o \textit{design} do \textit{BRAVO}.

% \begin{figure}[h]
%     \centering
%     \includegraphics[width=1.0\textwidth]{img/design.PNG}
%     \caption{\label{fig:design}\textcolor{blue}{\textit{Design} da proposta para o \textit{BRAVO}}}
% \end{figure}

Foram realizados dois cenários experimentais, utilizando 64 e 128 \textit{MFCCs}, respectivamente. Em ambos, o \textit{Autoencoder} foi treinado com dados de $X$. Em seguida treinamos uma rede neural densa multicamada para classificar a intensidade, treinada e validada apenas na porção dos dados resultantes da aplicação de $f$ em $X_{VIVAE}$, uma vez que $X_{VERBO}$ não tem correspondência com o contradomínio ($Z$) das intensidades.

Uma vez que não há \textit{label} correspondente às intensidades par $X_{VERBO}$. Então precisamos investigar se há algum sentido nos resultados quando aplicarmos a classificação a esses dados, que até então ainda não foram vistos pelo classificador.

Assim, faz-se necessária uma forma de analisar os registos de $X_{VIVAE}$ e$X_{VERBO}$ quanto às intensidades e a predição dessas intensidades, respectivamente. Podemos utilizar o \textit{PCA} (\textit{Principal Component Analysis}) para reduzir a dimensionalidade dos registros e observar o comportamento da classificação.

A utilização \textit{PCA} encontra registros na literatura, tanto de \textit{ML} e \textit{DL} aplicados a voz e emoções. Temos~\cite{pca1} que utilizou o PCA para gerar features de um modelo, observando que modelos treinados com as features obtidas a partir do PCA mantiveram sua performance quando comparados aos treinados com outros atributos;~\cite{pca2} que apesar de fazer uma \textit{feature selection} prévia, optou por utilizar o \textit{PCA} para reduzir em quase três vezes a dimensionalidade do dado para conseguir uma visualização bidimensional dos registros;~\cite{pca3} buscou desenvolver um sistema de reconhecimento de emoções para áudios com ruídos, utilizando dados $64$-dimensionais que seriam reduzidos para um espaço $6$-dimensional utilizando e comparando técnicas distintas, sendo uma delas o \textit{PCA}; e~\cite{pca5} que aproxima o grau de \textit{encoding} de um \textit{Autoencoder} linear - em seu espaço latente $n$-dimensional - ao de um PCA com $n$ componentes.

Então, sabemos  da utilização do \textit{PCA} tanto para permitir a visualização de dados através da redução de dimensionalidade quanto para gerar as \textit{features} utilizadas em modelos de reconhecimento de emoções. O que nos diz que o \textit{PCA} seria uma solução adequada para reduzir a dimensionalidade dos dados enquanto preserva características relevantes das amostras.


\section{Experimentos}

Nesta seção apresentaremos, detalhadamente, os resultados dos dois experimentos realizados. Ambos foram submetidos à mesma metodologia e aferição de métrica, o que nos possibilita comparar diretamente o desempenho oriundo das execuções.\\

\input{tex/5A_resultado_64}
\input{tex/5B_resultado_128}

\clearpage

\section{Discussão dos resultados}

Nesta seção iremos iniciar uma discussão sobre os resultados alcançados e apresentaremos as dificuldades encontradas, além das limitações gerais do projeto.\\

Com base nos resultados da Tabela \ref{table:resultexp} verificamos que o primeiro experimento obteve desempenho superior no que tange a métrica selecionada para o modelo de classificação de intensidade, tendo um \textit{F1-Score} superior aos do primeiro experimento em três das quatro classes.

Em ambos experimentos, a classe com pior resultado do classificador - de acordo a métrica definida na metodologia - foi semelhante, a classe Forte. E as classes com melhor desempenho são Fraca e Pico de intensidade, respectivamente.

Na Tabela \ref{table:compexp} vemos um ganho de desempenho superior a 7 vezes para o valor da \textit{Loss} no segundo experimento, no qual utilizamos um número maior de \textit{MFCCs}. Embora a \textit{Loss} tenha apresentado uma queda significativa no segundo experimento, o que significa que o \textit{Autoencoder} apresenta um desempenho melhor para reproduzir o dado de entrada, preservando melhor as características e atributos do dado, essa melhora no desempenho de uma função identidade se mostra contraditória frente o desempenho do segundo classificador. Então, podemos supor que uma quantidade estritamente maior de \textit{MFCCs} colaborou para a reconstrução da amostra enquanto não demonstrou ganhos semelhantes na sua utilização para classificar a intensidade da emoção.


% \begin{table}[!h]
%     \centering
%     \begin{tabular}{|l|cc|}
%     \hline
%         \multicolumn{1}{|c|}{\multirow{3}{*}{Intensidade}} & \multicolumn{2}{c|}{MFCCs}                                 \\ \cline{2-3} 
%         \multicolumn{1}{|c|}{}                             & \multicolumn{1}{c|}{64}                & 128               \\ \cline{2-3} 
%         \multicolumn{1}{|c|}{}                             & \multicolumn{1}{c|}{\textit{F1-Score}} & \textit{F1-Score} \\ \hline
%         Fraca                                              & \multicolumn{1}{c|}{\textbf{0,68}}     & 0,58              \\ \hline
%         Moderada                                           & \multicolumn{1}{c|}{\textbf{0,53}}     & 0,51              \\ \hline
%         Forte                                              & \multicolumn{1}{c|}{0,48}              & \textbf{0,49}     \\ \hline
%         Pico                                               & \multicolumn{1}{c|}{\textbf{0,66}}     & 0,64              \\ \hline
%     \end{tabular}
%     \caption{\label{table:resultexp}Comparativo de \textit{F1-Score} entre os experimentos}
% \end{table}

\begin{table}[]
    \centering
    \begin{tabular}{|l|l|l|}
    \hline
        Intensidade & F1-Score para 64 MFCCs & F1-Score para 128 MFCCs \\ \hline
        Fraca & \textbf{0,68} & 0,58 \\ \hline
        Moderada & \textbf{0,53} & 0,51 \\ \hline
        Forte & 0,48 & \textbf{0,49} \\ \hline
        Pico & \textbf{0,66} & 0,64 \\ \hline
    \end{tabular}
     \caption{\label{table:resultexp}Comparativo de \textit{F1-Score} entre os experimentos}
\end{table}

% \begin{table}[!h]
%     \centering
%     \begin{tabular}{|l|cc|}
%         \hline
%         \multicolumn{1}{|c|}{\multirow{2}{*}{Atributo do experimento}} & \multicolumn{2}{c|}{MFCCs}         \\ \cline{2-3} 
%         \multicolumn{1}{|c|}{}                                         & \multicolumn{1}{c|}{64}                & 128   \\ \hline
%         Melhor \textit{F1-Score}                                       & \multicolumn{1}{c|}{\textbf{0,68}}     & 0,64  \\ \hline
%         Classe com melhor \textit{F1-Score}                            & \multicolumn{1}{c|}{Fraca}             & Pico  \\ \hline
%         Pior \textit{F1-Score}                                         & \multicolumn{1}{c|}{\textbf{0,48}}     & 0,49  \\ \hline
%         Classe com pior \textit{F1-Score}                              & \multicolumn{1}{c|}{Forte}             & Forte \\ \hline
%         \textit{Loss} de teste (MSE)                                   & \multicolumn{1}{c|}{6,4}               & \textbf{0,84}  \\ \hline
%     \end{tabular}
%     \caption{\label{table:compexp}Comparativo de atributos de desempenho dos experimentos}
% \end{table}

\begin{table}[]
    \centering
    \begin{tabular}{|l|l|l|}
    \hline
        Resultado & MFCCs & ~ \\ \hline
        ~ & 64 & 128 \\ \hline
        Maior F1-Score & \textbf{0,68} & 0,64 \\ \hline
        Classe com maior F1-Score & Fraca & Pico \\ \hline
        Menor F1-Score & 0,48 & \textbf{0,49} \\ \hline
        Classe com menor F1-Score & Forte & Forte \\ \hline
    \end{tabular}
    \caption{\label{table:compexp}Comparativo de atributos de desempenho dos experimentos}
\end{table}

Embora nossa massa de dados seja composta por poucos registros - quando comparamos com outras bases de dados encontradas na literatura - de posse dos resultados dos experimentos, conseguimos observar que os vetores do espaço latente dos \textit{Autoencoders}, mesmo com uma redução de dimensionalidade à metade, aparentam manter características relativas a intensidade da emoção presentes ambos experimentos.

Quando agrupamos as classes Fraca e Moderada no cojunto denominado Baixo e Forte e Pico no conjunto denominado Alto, conseguimos observar nas Figuras \ref{fig:pca64-2} e \ref{fig:pca128-2} que mesmo com o desempenho superior do classificador do primeiro experimento, ainda há uma correspondência entre as intensidades dos registros. Uma vez que os \textit{labels} de $X_{VIVAE}$ são originais, observamos que as classes atribuídas aos dados de $X_{VERBO}$ parecem ser condizentes, vide o comportamento descendente da aumento da intensidade. Assim, o classificador aprendeu com $X_{VIVAE}$ a classificar a intensidade e aplicou essa lógica aos dados em $X_{VERBO}$.
