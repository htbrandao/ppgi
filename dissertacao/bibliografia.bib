@article{0,
  doi = {doi:10.5772/55406},
  author = {Shota Yamamoto and Yasunari Yoshitomi and Masayoshi Tabuse and Kou Kushida and Taro Asada},
  title = {Recognition of a Baby's Emotional Cry towards Robotics Baby Caregiver},
  journal = {International Journal of Advanced Robotic Systems},
  volume = {10},
  number = {2},
  pages = {86},
  year = {2013},
  doi = {10.5772/55406},
  url = {https://doi.org/10.5772/55406},
  eprint = {https://doi.org/10.5772/55406}
}
@misc{1,
  url = {https://arxiv.org/abs/2208.12812},
  author = {Elsayed, Nelly and ElSayed, Zag and Asadizanjani, Navid and Ozer, Murat and Abdelgawad, Ahmed and Bayoumi, Magdy},
  keywords = {Audio and Speech Processing (eess.AS), Human-Computer Interaction (cs.HC), Machine Learning (cs.LG), Sound (cs.SD), FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Speech Emotion Recognition using Supervised Deep Recurrent System for Mental Health Monitoring},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi = {10.48550/ARXIV.2208.12812},
}
@article{1.5,
  doi = {https://doi.org/10.1086/509092},
  author = {Phillip Lieberman},
  title = {The evolution of human speech: Its anatomical and neural bases},
  journal = {Current anthropology},
  volume = {48},
  number = {1},
  year = {2007},
  pages = {39--66}
}
@inproceedings{3,
  author={Rui Liu and Berrak Sisman and Björn Schuller and Guanglai Gao and Haizhou Li},
  title={{Accurate Emotion Strength Assessment for Seen and Unseen Speech Based on Data-Driven Deep Learning}},
  year={2022},
  booktitle={Proc. Interspeech 2022},
  pages={5493--5497},
  doi={10.21437/Interspeech.2022-534}
}
@article{4,
  title = {Emotional speaker identification using a novel capsule nets model},
  journal = {Expert Systems with Applications},
  volume = {193},
  pages = {116469},
  year = {2022},
  issn = {0957-4174},
  doi = {https://doi.org/10.1016/j.eswa.2021.116469},
  url = {https://www.sciencedirect.com/science/article/pii/S0957417421017498},
  author = {Ali Bou Nassif and Ismail Shahin and Ashraf Elnagar and Divya Velayudhan and Adi Alhudhaif and Kemal Polat},
  keywords = {Capsule network, Convolutional Neural Network, Emotional speech, Speaker Identification}
}
@misc{6,
  doi = {10.48550/ARXIV.2111.10783},
  url = {https://arxiv.org/abs/2111.10783},
  author = {Manoret, Pongpak and Chotipurk, Punnatorn and Sunpaweravong, Sompoom and Jantrachotechatchawan, Chanati and Duangrattanalert, Kobchai},
  keywords = {Sound (cs.SD), Human-Computer Interaction (cs.HC), Audio and Speech Processing (eess.AS), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},
  title = {Automatic Detection of Depression from Stratified Samples of Audio Data},
  publisher = {arXiv},
  year = {2021},
  copyright = {Creative Commons Attribution 4.0 International}
}
@misc{6.31,
  author = {NIH: National Institute on Deafness and Other Communication Disorders (NIDCD)},
  title = {What Is Voice? What Is Speech? What Is Language?},
  year = {2020},
  note = {\url{https://www.nidcd.nih.gov/health/voice-speech-and-language}}
}
@misc{8,
  doi = {10.48550/ARXIV.2102.06003},
  url = {https://arxiv.org/abs/2102.06003},
  author = {Sarkar, Uddalok and Nag, Sayan and Bhattacharya, Chirayata and Sanyal, Shankha and Banerjee, Archi and Sengupta, Ranjan and Ghosh, Dipak},
  keywords = {Sound (cs.SD), Computation and Language (cs.CL), Audio and Speech Processing (eess.AS), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},
  title = {Language Independent Emotion Quantification using Non linear Modelling of Speech},
  publisher = {arXiv},
  year = {2021},
  copyright = {Creative Commons Attribution 4.0 International}
}
@misc{11,
  doi = {10.48550/ARXIV.1303.1761},
  url = {https://arxiv.org/abs/1303.1761},
  author = {Bhargava, Mayank and Polzehl, Tim},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Improving Automatic Emotion Recognition from speech using Rhythm and Temporal feature},
  publisher = {arXiv},
  year = {2013},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
@misc{12,
  author = {Campos, Gabriel Almeida and Moutinho, Lucas da Silva},
  title = {DEEP: uma arquitetura para reconhecer emoção com base no espectro sonoro da voz de falantes da língua portuguesa},
  year = {2021},
  note = {\url{https://bdm.unb.br/handle/10483/27583}}
}
@inproceedings{12.12,
  title={Speech emotion recognition using deep neural network and extreme learning machine},
  author={Han, Kun and Yu, Dong and Tashev, Ivan},
  booktitle={Interspeech 2014},
  year={2014}
}
@article{12.16,
  title={Convolutional neural networks for speech recognition},
  author={Abdel-Hamid, Ossama and Mohamed, Abdel-rahman and Jiang, Hui and Deng, Li and Penn, Gerald and Yu, Dong},
  journal={IEEE/ACM Transactions on audio, speech, and language processing},
  volume={22},
  number={10},
  pages={1533--1545},
  year={2014},
  publisher={IEEE}
}
@article {12.21,
  article_type = {journal},
  title = {VERBO: Voice Emotion Recognition dataBase in Portuguese Language},
  author = {José Torres Neto and Geraldo P.R. Filho and Mano, Leandro Y. and Ueyama, João},
  volume = {14},
  number = {11},
  year = {2018},
  month = {Nov},
  pages = {1420-1430},
  doi = {10.3844/jcssp.2018.1420.1430},
  url = {https://thescipub.com/abstract/jcssp.2018.1420.1430},
  journal = {Journal of Computer Science},
  publisher = {Science Publications}
}
@book{12.23,
  title={Computational Intelligence: A Logical Approach},
  author={Poole, D.L. and Poole, D. and Mackworth, A.K. and Mackworth, A. and Goebel, R.},
  isbn={9780195102703},
  lccn={97009075},
  url={https://books.google.com.br/books?id=3p6KZSHjD4YC},
  year={1998},
  publisher={Oxford University Press}
}
@article{12.27,
  title={Hidden Markov models for speech recognition},
  author={Juang, Biing Hwang and Rabiner, Laurence R},
  journal={Technometrics},
  volume={33},
  number={3},
  pages={251--272},
  year={1991},
  publisher={Taylor \& Francis}
}
@article{12.28,
  doi = {0.1126/science.270.5234.303},
  author = {Robert V Shannon et al},
  title = {Speech recognition with primarily temporal cues},
  journal = {Science},
  volume = {270},
  number = {5234},
  year = {1995},
  pages = {303-304},
}
@inproceedings{14,
  author={Mashal, Sonia Xylina and Asnani, Kavita},
  booktitle={2017 International Conference on Computing Methodologies and Communication (ICCMC)},
  title={Emotion intensity detection for social media data},
  year={2017},
  volume={},
  number={},
  pages={155-158},
  doi={10.1109/ICCMC.2017.8282664}
}
@article{15,
  doi = {10.48550/ARXIV.1901.08458},
  url = {https://arxiv.org/abs/1901.08458},
  author = {Gaind, Bharat and Syal, Varun and Padgalwar, Sneha},
  keywords = {Social and Information Networks (cs.SI), Information Retrieval (cs.IR), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Emotion Detection and Analysis on Social Media},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
@article{16,
  doi = {https://doi.org/10.1038},
  author = {N Holz, P Larrouy-Maestri \& D Poeppel},
  title = {The paradoxical role of emotional intensity in the perception of vocal affect},
  journal = {Sci Rep},
  volume = {11},
  number = {9663},
  year = {2021},
  note = {\url{https://www.nature.com/articles/s41598-021-88431-0}}
}
@article{17,
  AUTHOR = {Dzedzickis, Andrius and Kaklauskas, Artūras and Bucinskas, Vytautas},
  TITLE = {Human Emotion Recognition: Review of Sensors and Methods},
  JOURNAL = {Sensors},
  VOLUME = {20},
  YEAR = {2020},
  NUMBER = {3},
  ARTICLE-NUMBER = {592},
  url = {https://www.mdpi.com/1424-8220/20/3/592},
  ISSN = {1424-8220},
  DOI = {10.3390/s20030592}
}
@article{18,
  doi = {10.1109/taffc.2022.3175578},
  url = {https://doi.org/10.1109/TAFFC.2022.3175578},
  year = 2022,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  pages = {1--1},
  author = {Kun Zhou and Berrak Sisman and Rajib Rana and Bjorn W. Schuller and Haizhou Li},
  title = {Emotion Intensity and its Control for Emotional Voice Conversion},
  journal = {{IEEE} Transactions on Affective Computing}
}
@article{18.12,
  title={The complexity of intensity: Issues concerning the structure of emotion intensity.},
  author={Frijda, Nico H and Ortony, Andrew and Sonnemans, Joep and Clore, Gerald L},
  year={1992},
  publisher={Sage Publications, Inc}
}
@article{18.46,
  title={Impact of intended emotion intensity on cue utilization and decoding accuracy in vocal expression of emotion.},
  author={Juslin and N Patrik and Laukka and Petri},
  journal={Emotion},
  volume={1},
  number={4},
  pages={381},
  year={2001},
  publisher={American Psychological Association}
}
@article{18.9,
  author = {James R Averill and Thomas A More},
  title = {Happiness},
  journal = {Handbook of emotions},
  publisher = {The Guilford Press},
  year = {1993},
  pages = {617–629},
  note = {\url{https://psycnet.apa.org/record/1993-98937-037}}
}
@article{20,
  AUTHOR = {Islam, Md. Riadul and Akhand, M. A. H. and Kamal, Md Abdus Samad and Yamada, Kou},
  TITLE = {Recognition of Emotion with Intensity from Speech Signal Using 3D Transformed Feature and Deep Learning},
  JOURNAL = {Electronics},
  VOLUME = {11},
  YEAR = {2022},
  NUMBER = {15},
  ARTICLE-NUMBER = {2362},
  url = {https://www.mdpi.com/2079-9292/11/15/2362},
  ISSN = {2079-9292},
  DOI = {10.3390/electronics11152362}
}
@ARTICLE{20.10,
  author={Hamsa, Shibani and Shahin, Ismail and Iraqi, Youssef and Werghi, Naoufel},  journal={IEEE Access},
  title={Emotion Recognition From Speech Using Wavelet Packet Transform Cochlear Filter Bank and Random Forest Classifier},
  year={2020},
  volume={8},
  number={},
  pages={96994-97006},
  doi={10.1109/ACCESS.2020.2991811}
}
@article{20.11,
  title = {Acoustic feature selection for automatic emotion recognition from speech},
  journal = {Information Processing \& Management},
  volume = {45},
  number = {3},
  pages = {315-328},
  year = {2009},
  issn = {0306-4573},
  doi = {https://doi.org/10.1016/j.ipm.2008.09.003},
  url = {https://www.sciencedirect.com/science/article/pii/S0306457308000885},
  author = {Jia Rong and Gang Li and Yi-Ping Phoebe Chen},
  keywords = {Emotion recognition, Feature selection, Machine learning},
}
@article{20.13,
  title = {SVM Scheme for Speech Emotion Recognition using MFCC Feature},
  author = {A. Milton and S. Sharmy Roy and S. Samil Selvi},
  journal = {International Journal of Computer Applications},
  volume = {69},
  number = {9},
  pages = {34--49},
  year = {2013},
  doi = {},
  note = {\url{https://research.ijcaonline.org/volume69/number9/pxc3887667.pdf}}
}
@article{20.15,
  title = {Implementation and Comparison of Speech Emotion Recognition System Using Gaussian Mixture Model (GMM) and K- Nearest Neighbor (K-NN) Techniques},
  journal = {Procedia Computer Science},
  volume = {49},
  pages = {50-57},
  year = {2015},
  note = {Proceedings of 4th International Conference on Advances in Computing, Communication and Control (ICAC3'15)},
  issn = {1877-0509},
  doi = {https://doi.org/10.1016/j.procs.2015.04.226},
  url = {https://www.sciencedirect.com/science/article/pii/S1877050915007358},
  author = {Rahul B. Lanjewar and Swarup Mathurkar and Nilesh Patel},
  keywords = {Speech Features, Emotion, MFCC, wavelet, pitch, K-NN, GMM, Database},
}
@INPROCEEDINGS{20.7,
  author={Nakatsu, R. and Nicholson, J. and Tosa, N.},
  booktitle={1999 IEEE Third Workshop on Multimedia Signal Processing (Cat. No.99TH8451)},
  title={Emotion recognition and its application to computer agents with spontaneous interactive capabilities},
  year={1999},
  volume={},
  number={},
  pages={439-444},
  doi={10.1109/MMSP.1999.793887}
}
@article{21,
  author = {Neelakshi Josh},
  title = {Brazilian Portuguese emotional speech corpus analysis},
  journal = {X Seminário em TI do PCI/CT},
  volume = {},
  year = {2021},
  note = {\url{https://www.gov.br/cti/pt-br/publicacoes/producao-cientifica/seminario-pci/xi_seminario_pci-2021/pdf/seminario-2021_paper_29.pdf}}
}
@article{25,
  doi = {10.1017/S0954579405050340},
  author = {Posner J, Russell JA, Peterson BS},
  title = {The circumplex model of affect: an integrative approach to affective neuroscience, cognitive development, and psychopathology},
  journal = {Dev Psychopathol},
  volume = {15},
  number = {3},
  year = {2005},
  pages = {715-34},
  note = {\url{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2367156/}}
}
@article{27,
  title = {O afeto sob a perspectiva do circumplexo: evidências de validade de construto},
  journal = {Avaliação Psicológica},
  author={Crispim, Ana Carla AND Cruz, Roberto Moraes AND Oliveira, Cassandra Melo AND Archer, Aline Battisti},
  ISSN = {1677-0471},
  language = {pt},
  url = {\url{http://pepsic.bvsalud.org/scielo.php?script=sci_arttext&pid=S1677-04712017000200005&nrm=iso}},
  volume = {16},
  year = {2017},
  month = {04},
  pages = {145 - 152},
  publisher = {scielopepsic},
  doi = {http://dx.doi.org/10.15689/AP.2017.1602.04},
}
@article{28,
  author={Akhtar, Md Shad and Ghosal, Deepanway and Ekbal, Asif and Bhattacharyya, Pushpak and Kurohashi, Sadao},
  journal={IEEE Transactions on Affective Computing},
  title={All-in-One: Emotion, Sentiment and Intensity Prediction Using a Multi-Task Ensemble Framework},
  year={2022},
  volume={13},
  number={1},
  pages={285-297},
  doi={10.1109/TAFFC.2019.2926724}
}
@inproceedings{31.1,
  author={Schuller, Björn and Vlasenko, Bogdan and Eyben, Florian and Rigoll, Gerhard and Wendemuth, Andreas},
  booktitle={2009 IEEE Workshop on Automatic Speech Recognition \& Understanding},
  title={Acoustic emotion recognition: A benchmark comparison of performances},
  year={2009},
  volume={},
  number={},
  pages={552-557},
  doi={10.1109/ASRU.2009.5372886}
}
@article{31.11,
  title={The nature of emotions: Human emotions have deep evolutionary roots, a fact that may explain their complexity and provide tools for clinical practice},
  author={Plutchik, Robert},
  journal={American scientist},
  volume={89},
  number={4},
  pages={344--350},
  year={2001},
  publisher={JSTOR}
}
@article{31.9,
  author = { Paul Ekman },
  title = {An argument for basic emotions},
  journal = {Cognition and Emotion},
  volume = {6},
  number = {3-4},
  pages = {169-200},
  year  = {1992},
  publisher = {Routledge},
  doi = {10.1080/02699939208411068},
  url = {https://doi.org/10.1080/02699939208411068},
  eprint = {https://doi.org/10.1080/02699939208411068}
}
@article{31.10,
  title={A circumplex model of affect.},
  author={Russell, James A},
  journal={Journal of personality and social psychology},
  volume={39},
  number={6},
  pages={1161},
  year={1980},
  publisher={American Psychological Association}
}
@article{32,
  AUTHOR = {Abbaschian, Babak Joze and Sierra-Sosa, Daniel and Elmaghraby, Adel},
  TITLE = {Deep Learning Techniques for Speech Emotion Recognition, from Databases to Models},
  JOURNAL = {Sensors},
  VOLUME = {21},
  YEAR = {2021},
  NUMBER = {4},
  ARTICLE-NUMBER = {1249},
  url = {https://www.mdpi.com/1424-8220/21/4/1249},
  PubMedID = {33578714},
  ISSN = {1424-8220},
}
@article{32.25,
  author={Zhang, Shiqing and Zhang, Shiliang and Huang, Tiejun and Gao, Wen},
  journal={IEEE Transactions on Multimedia},
  title={Speech Emotion Recognition Using Deep Convolutional Neural Network and Discriminant Temporal Pyramid Matching},
  year={2018},
  volume={20},
  number={6},
  pages={1576-1590},
  doi={10.1109/TMM.2017.2766843}}
@inproceedings{32.3,
  title={Sentic Computing: Exploitation of Common Sense for the Development of Emotion-Sensitive Systems},
  author={E. Cambria and Amir Hussain and Catherine Havasi and Chris Eckl},
  booktitle={COST 2102 Training School},
  year={2009}
}
@article{32.30,
  title = {Speech emotion recognition using deep 1D \& 2D CNN LSTM networks},
  journal = {Biomedical Signal Processing and Control},
  volume = {47},
  pages = {312-323},
  year = {2019},
  issn = {1746-8094},
  doi = {https://doi.org/10.1016/j.bspc.2018.08.035},
  url = {https://www.sciencedirect.com/science/article/pii/S1746809418302337},
  author = {Jianfeng Zhao and Xia Mao and Lijiang Chen},
  keywords = {Speech emotion recognition, CNN LSTM network, Raw audio clips, Log-mel spectrograms},
}
@misc{32.31,
  doi = {10.48550/ARXIV.1712.08708},
  url = {https://arxiv.org/abs/1712.08708},
  author = {Latif, Siddique and Rana, Rajib and Qadir, Junaid and Epps, Julien},
  keywords = {Sound (cs.SD), Machine Learning (cs.LG), Audio and Speech Processing (eess.AS), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},
  title = {Variational Autoencoders for Learning Latent Representations of Speech Emotion: A Preliminary Study},
  publisher = {arXiv},
  year = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
@article{32.32,
  title={Ensemble methods for spoken emotion recognition in call-centres},
  author={Morrison, Donn and Wang, Ruili and De Silva, Liyanage C},
  journal={Speech communication},
  volume={49},
  number={2},
  pages={98--112},
  year={2007},
  publisher={Elsevier}
}
@inproceedings{32.55,
  title={A database of German emotional speech},
  author={Felix Burkhardt and Astrid Paeschke and M. Rolfes and Walter F. Sendlmeier and Benjamin Weiss},
  booktitle={Interspeech},
  year={2005}
}
@inproceedings{32.56,
  author = {Inger S. Engberg and Anya V. Hansen and Ove Andersen and Paul Dalsgaard},
  title = {DESIGN, RECORDING AND VERIFICATION OF A
  DANISH EMOTIONAL SPEECH DATABASE},
  journal = {Proceedings of the Fifth European Conference on Speech Communication and Technology},
  year = {1997},
  note = {\url{https://www.isca-speech.org/archive_v0/archive_papers/eurospeech_1997/e97_1695.pdf}}
}
@article{32.57,
  title={The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS): A dynamic, multimodal set of facial and vocal expressions in North American English},
  author={Livingstone, Steven R and Russo, Frank A},
  journal={PloS one},
  volume={13},
  number={5},
  pages={e0196391},
  year={2018},
  publisher={Public Library of Science}
}
@article{32.58,
  title={Intelligibility of emotional speech in younger and older adults},
  author={Dupuis, Kate and Pichora-Fuller, M Kathleen},
  journal={Ear and hearing},
  volume={35},
  number={6},
  pages={695--707},
  year={2014},
  publisher={LWW}
}
@article{32.59,
  author={Cao, Houwei and Cooper, David G. and Keutmann, Michael K. and Gur, Ruben C. and Nenkova, Ani and Verma, Ragini},
  journal={IEEE Transactions on Affective Computing},
  title={CREMA-D: Crowd-Sourced Emotional Multimodal Actors Dataset},
  year={2014},
  volume={5},
  number={4},
  pages={377-390},
  doi={10.1109/TAFFC.2014.2336244}
}
@book{32.74,
  author = {D Kriesel},
  title = {A Brief Introduction to Neural Networks},
  pages = {21–-25},
  year = {2021},
  note = {\url{http://www.dkriesel.com}}
}
@inproceedings{32.79,
  title={Negative emotion recognition using deep learning for thai language},
  author={Mekruksavanich, Sakorn and Jitpattanakul, Anuchit and Hnoohom, Narit},
  booktitle={2020 joint international conference on digital arts, media and technology with ECTI northern section conference on electrical, electronics, computer and telecommunications engineering (ECTI DAMT \& NCON)},
  pages={71--74},
  year={2020},
  organization={IEEE}
}
@inproceedings{32.89,
  title={Data Augmentation Using GANs for Speech Emotion Recognition.},
  author={Chatziagapi, Aggelina and Paraskevopoulos, Georgios and Sgouropoulos, Dimitris and Pantazopoulos, Georgios and Nikandrou, Malvina and Giannakopoulos, Theodoros and Katsamanis, Athanasios and Potamianos, Alexandros and Narayanan, Shrikanth},
  booktitle={Interspeech},
  pages={171--175},
  year={2019}
}
@inproceedings{32.95,
  title={Improved End-to-End Speech Emotion Recognition Using Self Attention Mechanism and Multitask Learning.},
  author={Li, Yuanchao and Zhao, Tianyu and Kawahara, Tatsuya},
  booktitle={Interspeech},
  pages={2803--2807},
  year={2019}
}
@inproceedings{34,
  author={Eskimez, Sefik Emre and Duan, Zhiyao and Heinzelman, Wendi},
  booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title={Unsupervised Learning Approach to Feature Analysis for Automatic Speech Emotion Recognition},
  year={2018},
  volume={},
  number={},
  pages={5099-5103},
  doi={10.1109/ICASSP.2018.8462685}
}
@article{35.16,
  author = {Barlow, H.B.},
  title = "{Unsupervised Learning}",
  journal = {Neural Computation},
  volume = {1},
  number = {3},
  pages = {295-311},
  year = {1989},
  month = {09},
  issn = {0899-7667},
  doi = {10.1162/neco.1989.1.3.295},
  url = {https://doi.org/10.1162/neco.1989.1.3.295},
  eprint = {https://direct.mit.edu/neco/article-pdf/1/3/295/811863/neco.1989.1.3.295.pdf},
}
@inproceedings{35.17,
  title={Extracting domain invariant features by unsupervised learning for robust automatic speech recognition},
  author={Hsu, Wei-Ning and Glass, James},
  booktitle={2018 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={5614--5618},
  year={2018},
  organization={IEEE}
}
@inproceedings{35.18,
  title={Sparse autoencoder-based feature transfer learning for speech emotion recognition},
  author={Deng, Jun and Zhang, Zixing and Marchi, Erik and Schuller, Bj{\"o}rn},
  booktitle={2013 humaine association conference on affective computing and intelligent interaction},
  pages={511--516},
  year={2013},
  organization={IEEE}
}
@article{35.19,
  author={Deng, Jun and Zhang, Zixing and Eyben, Florian and Schuller, Björn},
  journal={IEEE Signal Processing Letters},
  title={Autoencoder-based Unsupervised Domain Adaptation for Speech Emotion Recognition},
  year={2014},
  volume={21},
  number={9},
  pages={1068-1072},
  doi={10.1109/LSP.2014.2324759}
}
@article{37.50,
  title={Direct modelling of speech emotion from raw speech},
  author={Latif, Siddique and Rana, Rajib and Khalifa, Sara and Jurdak, Raja and Epps, Julien},
  journal={arXiv preprint arXiv:1904.03833},
  year={2019}
}
@inproceedings{37.125,
  title={Speech emotion recognition from spectrograms with deep convolutional neural network},
  author={Badshah, Abdul Malik and Ahmad, Jamil and Rahim, Nasir and Baik, Sung Wook},
  booktitle={2017 international conference on platform technology and service (PlatCon)},
  pages={1--5},
  year={2017},
  organization={IEEE}
}
@inproceedings{37.126,
  title={An experimental study of speech emotion recognition based on deep convolutional neural networks},
  author={Zheng, WQ and Yu, JS and Zou, YX},
  booktitle={2015 international conference on affective computing and intelligent interaction (ACII)},
  pages={827--831},
  year={2015},
  organization={IEEE}
}
@inproceedings{37.127,
  title={Learning salient features for speech emotion recognition using CNN},
  author={Liu, Jiamu and Han, Wenjing and Ruan, Huabin and Chen, Xiaomin and Jiang, Dongmei and Li, Haifeng},
  booktitle={2018 First Asian Conference on Affective Computing and Intelligent Interaction (ACII Asia)},
  pages={1--5},
  year={2018},
  organization={IEEE}
}
@inproceedings{37.128,
  title={Learning spectro-temporal features with 3D CNNs for speech emotion recognition},
  author={Kim, Jaebok and Truong, Khiet P and Englebienne, Gwenn and Evers, Vanessa},
  booktitle={2017 Seventh International Conference on Affective Computing and Intelligent Interaction (ACII)},
  pages={383--388},
  year={2017},
  organization={IEEE}
}

@article{38,
  doi = {https://doi.org/10.1007/s40747-021-00295-z},
  author = {P.T. Krishnan and Joseph A. N. Raj and V. Rajangam},
  title = {Emotion classification from speech signal based on empirical mode decomposition and non-linear features},
  journal = {Complex Intell. Syst.},
  volume = {7},
  number = {},
  year = {2021},
  pages = {1919-1934},
  note = {\url{https://link.springer.com/article/10.1007/s40747-021-00295-z}}
}
@article{39,
  doi = {https://doi.org/10.1007/s10772-011-9125-1},
  author = {S. G. Koolagudi and K. S. Rao},
  title = {Emotion recognition from speech: a review},
  journal = {Int J Speech Technol},
  volume = {15},
  number = {},
  year = {2012},
  pages = {99-–117},
  note = {\url{https://link.springer.com/article/10.1007/s10772-011-9125-1}}
}
@article{49,
  author={Zheng, Yu},
  journal={IEEE Transactions on Big Data},
  title={Methodologies for Cross-Domain Data Fusion: An Overview},
  year={2015},
  volume={1},
  number={1},
  pages={16-34},
  doi={10.1109/TBDATA.2015.2465959}
}
@booklet{51,
  author = {Mara Behlau},
  title = {RESPOSTAS PARA PERGUNTASFREQUENTES NA ÁREA DE VOZ},
  publisher = {SOCIEDADE BRASILEIRA DE FONOAUDIOLOGIA},
  year = {2009},
  note = {\url{https://www.sbfa.org.br/campanhadavoz/FAQs2011.pdf}}
}
@book{53,
  title={Deep Learning},
  author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
  publisher={MIT Press},
  note={\url{http://www.deeplearningbook.org}},
  year={2016}
}
@article{57,
  author = {Robert Plutchik},
  title = {The Nature of Emotions: Human Emotions Have Deep Evolutionary Roots, a Fact That May Explain Their Complexity and Provide Tools for Clinical Practice},
  journal = {American Scientist},
  volume = {89},
  number = {4},
  year = {2001},
  pages = {344-350},
  note = {\url{http://www.jstor.org/stable/27857503}}
}
@book{58,
  title={Deep Learning},
  author={Josh Patterson and Adam Gibson},
  publisher={O'Reilly Media, Inc.},
  note={\url{https://www.oreilly.com/library/view/deep-learning/9781491924570/?_gl=1*5isuuh*_ga*MTc2MTkyMzUxLjE2NzE5MTM2OTA.*_ga_092EL089CH*MTY3MTkxMzY5MC4xLjEuMTY3MTkxNTE3MC41Ny4wLjA.}},
  year={2017}
}
@article{59,
  author={Zheng, Yu},
  journal={IEEE Transactions on Big Data},
  title={Methodologies for Cross-Domain Data Fusion: An Overview},
  year={2015},
  volume={1},
  number={1},
  pages={16-34},
  doi={10.1109/TBDATA.2015.2465959}
}
@article{60,
  title={{Better latent spaces for better autoencoders}},
  author={Barry M. Dillon and Tilman Plehn and Christof Sauer and Peter Sorrenson},
  journal={SciPost Phys.},
  volume={11},
  pages={061},
  year={2021},
  publisher={SciPost},
  doi={10.21468/SciPostPhys.11.3.061},
  note={\url{https://scipost.org/10.21468/SciPostPhys.11.3.061}}
}
@article{61,
  title={Comparing deep neural networks against humans: object recognition when the signal gets weaker},
  author={Geirhos, Robert and Janssen, David HJ and Sch{\"u}tt, Heiko H and Rauber, Jonas and Bethge, Matthias and Wichmann, Felix A},
  journal={arXiv preprint arXiv:1706.06969},
  year={2017}
}
@book{62,
  author = {D. Purves and G. J. Augustine GJ and D. Fitzpatrick D and et al.},
  title = {Neuroscience},
  chapter = {13},
  year = {2001},
  publisher = {Sunderland (MA): Sinauer Associates},
  note = {\url{https://www.ncbi.nlm.nih.gov/books/NBK10924}}
}
@inproceedings{63,
  author={Zhu, Xiaolian and Yang, Shan and Yang, Geng and Xie, Lei},
  booktitle={2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  title={Controlling Emotion Strength with Relative Attribute for End-to-End Speech Synthesis},
  year={2019},
  volume={},
  number={},
  pages={192-199},
  doi={10.1109/ASRU46091.2019.9003829}
}
@article{64,
  title = {Traffic density classification using sound datasets: An empirical study on traffic flow at asymmetric roads},
  author = {Bui, Khac-Hoai Nam and Oh, Hyeonjeong and Yi, Hongsuk},
  journal = {IEEE Access},
  volume = {8},
  pages = {125671--125679},
  year = {2020},
  publisher = {IEEE},
  note = {\url{https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9136653}}
}
@article{65,
  title={Evaluation metrics for unsupervised learning algorithms},
  author={Palacio-Ni{\~n}o, Julio-Omar and Berzal, Fernando},
  journal={arXiv preprint arXiv:1905.05667},
  year={2019},
  note = {\url{https://arxiv.org/pdf/1905.05667.pdf}}
}
@INPROCEEDINGS{66,
  author={Zhou, Kun and Sisman, Berrak and Liu, Rui and Li, Haizhou},
  booktitle={ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Seen and Unseen Emotional Style Transfer for Voice Conversion with A New Emotional Speech Dataset}, 
  year={2021},
  volume={},
  number={},
  pages={920-924},
  doi={10.1109/ICASSP39728.2021.9413391}},
  note={\url{https://ieeexplore.ieee.org/document/9413391}}
}
@article{emoint1,
  title={Emotional intensity: Measurement and theoretical implications},
  author={Bachorowski, Jo-Anne and Braaten, Ellen B},
  journal={Personality and individual differences},
  volume={17},
  number={2},
  pages={191--199},
  year={1994},
  publisher={Elsevier},
  note={\url{https://www.sciencedirect.com/science/article/abs/pii/0191886994900256}}
}
@misc{emoint2,
  title={A medida funcional da intensidade das emoções},
  author={Oliveira, Armando M and Cardoso, Francisco M and Teixeira, Marta},
  year={2001},
  publisher={Trabalho desenvolvido no âmbito do projecto POCTI/PSI/41235},
  note={\url{https://psicologiaeeducacao.ubi.pt/Ficheiros/ArquivoHistorico/VOL1/PE%20N1e2/PE%20N1e2_index_10_.pdf}}
}
@article{emoint2.1,
  title={The structure of subjective emotional intensity},
  author={Sonnemans, Joep and Frijda, Nico H},
  journal={Cognition \& Emotion},
  volume={8},
  number={4},
  pages={329--350},
  year={1994},
  publisher={Taylor \& Francis}
}
@article{emoint3,
  title={Desenvolvimento e validação de uma escala de afetos positivos e negativos},
  author={Zanon, Cristian and Bastianello, Micheline Roat and Pacico, Juliana Cerentini and Hutz, Claudio Simon},
  journal={Psico-UsF},
  volume={18},
  pages={193--201},
  year={2013},
  publisher={SciELO Brasil},
  note={\url{https://www.scielo.br/j/pusf/a/vh7QqFWQLYx5dBptgfQHBJS/?format=pdf&lang=pt}}
}
@article{panas1,
  title={Structural validity and reliability of the Positive and Negative Affect Schedule (PANAS): Evidence from a large Brazilian community sample},
  author={Carvalho, Hudson W de and Andreoli, S{\'e}rgio B and Lara, Diogo R and Patrick, Christopher J and Quintana, Maria In{\^e}s and Bressan, Rodrigo A and Melo, Marcelo F de and Mari, Jair de J and Jorge, Miguel R},
  journal={Brazilian Journal of Psychiatry},
  volume={35},
  pages={169--172},
  year={2013},
  publisher={SciELO Brasil},
  note={\url{https://www.scielo.br/j/rbp/a/qLd5P5VfpLRfF5qDmBxTCQS/?lang=en}}
}
@article{panas2,
  title={An{\'a}lise psicom{\'e}trica da PANAS no Brasil},
  author={Otsuka Nunes, Lucas Yukio and Campos Lopes Lemos, Daniel and de Castro Ribas J{\'u}nior, Rodolfo and Brand{\~a}o Behar, Cl{\'a}udia and Pires dos Santos, Pedro Paulo},
  journal={Ciencias Psicol{\'o}gicas},
  volume={13},
  number={1},
  pages={45--55},
  year={2019},
  publisher={Facultad de Psicología-Universidad Católica del Uruguay.},
  note={\url{https://www.redalyc.org/journal/4595/459559717005/html/}}
}
@misc{adam,
  title={Adam: A Method for Stochastic Optimization}, 
  author={Diederik P. Kingma and Jimmy Ba},
  year={2017},
  eprint={1412.6980},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  note={\url{https://arxiv.org/abs/1412.6980}}
}
@INPROCEEDINGS{pca1,
  author={Chul Min Lee and Narayanan, S.S. and Pieraccini, R.},
  booktitle={Proceedings. IEEE International Conference on Multimedia and Expo}, 
  title={Classifying emotions in human-machine spoken dialogs}, 
  year={2002},
  volume={1},
  number={},
  pages={737-740 vol.1},
  doi={10.1109/ICME.2002.1035887},
  note={\url{https://ieeexplore.ieee.org/document/1035887}}
}
@INPROCEEDINGS{pca2,
  author={Ververidis, D. and Kotropoulos, C. and Pitas, I.},
  booktitle={2004 IEEE International Conference on Acoustics, Speech, and Signal Processing}, 
  title={Automatic emotional speech classification}, 
  year={2004},
  volume={1},
  number={},
  pages={I-593},
  doi={10.1109/ICASSP.2004.1326055},
  note={\url{https://ieeexplore.ieee.org/document/1326055}}
}
@INPROCEEDINGS{pca3,
  author={You, Mingyu and Chen, Chun and Bu, Jiajun and Liu, Jia and Tao, Jianhua},
  booktitle={2006 IEEE International Conference on Multimedia and Expo}, 
  title={Emotion Recognition from Noisy Speech}, 
  year={2006},
  volume={},
  number={},
  pages={1653-1656},
  doi={10.1109/ICME.2006.262865},
  note={\url{https://ieeexplore.ieee.org/document/4036934}}
}
@INPROCEEDINGS{pca4,
  author={You, Mingyu and Chen, Chun and Bu, Jiajun and Liu, Jia and Tao, Jianhua},
  booktitle={2006 IEEE International Symposium on Industrial Electronics}, 
  title={A Hierarchical Framework for Speech Emotion Recognition}, 
  year={2006},
  volume={1},
  number={},
  pages={515-519},
  doi={10.1109/ISIE.2006.295649},
  note={\url{}}
}
@article{pca5,
  title={Emotion recognition from speech: an unsupervised learning approach},
  author={Rovetta, Stefano and Mnasri, Zied and Masulli, Francesco and Cabri, Alberto and others},
  journal={International Journal of Computational Intelligence Systems},
  volume={14},
  number={1},
  pages={23--35},
  year={2020},
  publisher={Atlantis Press},
  note={\url{https://air.unimi.it/bitstream/2434/955219/1/03-125945494.pdf}}
}
@Article{pca6,
AUTHOR = {Olatinwo, Damilola D. and Abu-Mahfouz, Adnan and Hancke, Gerhard and Myburgh, Hermanus},
TITLE = {IoT-Enabled WBAN and Machine Learning for Speech Emotion Recognition in Patients},
JOURNAL = {Sensors},
VOLUME = {23},
YEAR = {2023},
NUMBER = {6},
ARTICLE-NUMBER = {2948},
URL = {https://www.mdpi.com/1424-8220/23/6/2948},
PubMedID = {36991659},
ISSN = {1424-8220},
DOI = {10.3390/s23062948}
}
@book{alexa1,
  title={Smart environments: technology, protocols, and applications},
  author={Cook, Diane and Das, Sajal Kumar},
  volume={43},
  year={2004},
  publisher={John Wiley \& Sons}
}
@inproceedings{alexa2,
  title={" Alexa is my new BFF" social roles, user satisfaction, and personification of the Amazon Echo},
  author={Purington, Amanda and Taft, Jessie G and Sannon, Shruti and Bazarova, Natalya N and Taylor, Samuel Hardman},
  booktitle={Proceedings of the 2017 CHI conference extended abstracts on human factors in computing systems},
  pages={2853--2859},
  year={2017}
}
@misc{bsignal0,
  title = {AI-Mediated Conversations (AI-MC) Redefining Bank’s Revenues Through its Call Center},
  howpublished = {\url{https://behavioralsignals.com/ai-mediated-conversations-case-study/}},
  note = {Accessed: 2023-08-18}
}
@misc{bsignal1,
  title = {EmotionAI and Customer Satisfaction in the Financial Services},
  howpublished = {\url{https://behavioralsignals.com/emotionai-and-customer-satisfaction-in-the-financial-services/}},
  note = {Accessed: 2023-08-18}
}
@misc{bsignal2,
  title = {How Behavioral AI can transform efficiency and quality of customer conversations by over 20%},
  howpublished = {\url{https://behavioralsignals.com/how-behavioral-ai-can-transform-efficiency-and-quality-of-customer-conversations-webinar/}},
  note = {Accessed: 2023-08-18}
}
@INPROCEEDINGS{complexidade1,
  author={Sonmez, YeSim Ülgen and Varol, Asaf},
  booktitle={2019 7th International Symposium on Digital Forensics and Security (ISDFS)}, 
  title={New Trends in Speech Emotion Recognition}, 
  year={2019},
  volume={},
  number={},
  pages={1-7},
  doi={10.1109/ISDFS.2019.8757528}}
@article{img_russel,
  author = {Nogueira, Kennyo},
  year = {2018},
  month = {06},
  pages = {1},
  title = {Estudo de respostas emocionais às cores no contexto de cartazes de cinema},
  volume = {8},
  journal = {Design e Tecnologia},
  doi = {10.23972/det2018iss15pp1-11}
}
@article{img_iavsmlvsdl,
  author = {Bhatt, Chandradeep and Kumar, Indrajeet and Vijayakumar, · and Kamred, · and Singh, Kamred and Kumar, Abhishek},
  year = {2021},
  month = {08},
  pages = {},
  title = {The state of the art of deep learning models in medical science and their challenges},
  volume = {27},
  journal = {Multimedia Systems},
  doi = {10.1007/s00530-020-00694-1}
}